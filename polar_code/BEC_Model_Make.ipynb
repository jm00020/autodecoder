{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense, Input, Add\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "from Source import BEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_power=7\n",
    "CodeRate=0.5\n",
    "N_length=int(2**n_power)\n",
    "msg_length=int(CodeRate*N_length)\n",
    "frozen_length=N_length-msg_length\n",
    "TotalNumMessage=4\n",
    "codeNum = 10**6 \n",
    "test_codeNum = 10**3\n",
    "\n",
    "Prob_start=0.15\n",
    "Prob_delta=0.05\n",
    "BEC_count=8\n",
    "BECs=np.arange(Prob_start,Prob_start+BEC_count*Prob_delta,Prob_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_All=BEC.AllGeneratorMatrixPolarCode(n_power) ###생성행렬생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Z_BEC,Z_decending_index_BEC)=BEC.BhanttacharyyaParameterBEC(N_length, n_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectedBitsPositions = Z_decending_index_BEC[frozen_length:]\n",
    "SelectedBitsPositions.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrozenBitsPositions = Z_decending_index_BEC[:frozen_length]\n",
    "FrozenBitsPositions.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg, codeword = BEC.Encoding(codeNum, N_length, n_power, msg_length, SelectedBitsPositions, G_All[n_power]) \n",
    "ReceviedBEC = BEC.ReceviedCode(0.25, codeNum, N_length, codeword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_msg, test_codeword = BEC.Encoding(test_codeNum, N_length, n_power, msg_length, SelectedBitsPositions, \n",
    "                                       G_All[n_power]) \n",
    "test_ReceviedBEC = BEC.ReceviedCode(0.25, test_codeNum, N_length, test_codeword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(128,))\n",
    "line1_Dense1 = Dense(128*1, activation='elu')(input_layer)\n",
    "line1_Dense2 = Dense(128*1, activation='elu')(line1_Dense1)         \n",
    "line1_Dense3 = Dense(128*1, activation='elu')(line1_Dense2)\n",
    "line1_output_layer = Dense(128, activation='tanh')(line1_Dense3)\n",
    "\n",
    "line2_Dense1 = Dense(128*2, activation='elu')(input_layer)\n",
    "line2_Dense2 = Dense(128*4, activation='elu')(line2_Dense1)         \n",
    "line2_Dense3 = Dense(128*2, activation='elu')(line2_Dense2)\n",
    "line2_output_layer = Dense(128, activation='tanh')(line2_Dense3)\n",
    "\n",
    "line3_Dense1 = Dense(128*3, activation='elu')(input_layer)\n",
    "line3_Dense2 = Dense(128*9, activation='elu')(line3_Dense1)         \n",
    "line3_Dense3 = Dense(128*3, activation='elu')(line3_Dense2)\n",
    "line3_output_layer = Dense(128, activation='tanh')(line3_Dense3)\n",
    "\n",
    "line4_Dense1 = Dense(128*4, activation='elu')(input_layer)\n",
    "line4_Dense2 = Dense(128*16, activation='elu')(line4_Dense1)         \n",
    "line4_Dense3 = Dense(128*4, activation='elu')(line4_Dense2)\n",
    "line4_output_layer = Dense(128, activation='tanh')(line4_Dense3)\n",
    "\n",
    "line5_Dense1 = Dense(128*5, activation='elu')(input_layer)\n",
    "line5_Dense2 = Dense(128*25, activation='elu')(line5_Dense1)         \n",
    "line5_Dense3 = Dense(128*5, activation='elu')(line5_Dense2)\n",
    "line5_output_layer = Dense(128, activation='tanh')(line5_Dense3)\n",
    "\n",
    "line6_Dense1 = Dense(128*6, activation='elu')(input_layer)\n",
    "line6_Dense2 = Dense(128*36, activation='elu')(line6_Dense1)         \n",
    "line6_Dense3 = Dense(128*6, activation='elu')(line6_Dense2)\n",
    "line6_output_layer = Dense(128, activation='tanh')(line6_Dense3)\n",
    "\n",
    "add_layer = Add()([line1_output_layer, line2_output_layer, line3_output_layer, line4_output_layer, \n",
    "                   line5_output_layer, line6_output_layer])\n",
    "\n",
    "output_layer = Dense(128, activation='linear')(add_layer)\n",
    "\n",
    "model = Model(inputs = input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000/1000000 [==============================] - 18s 18us/step - loss: 0.0649 - acc: 0.0196 - val_loss: 0.0660 - val_acc: 0.0220\n",
      "Epoch 31/100\n",
      "1000000/1000000 [==============================] - 18s 18us/step - loss: 0.0649 - acc: 0.0203 - val_loss: 0.0658 - val_acc: 0.0230\n",
      "Epoch 32/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0648 - acc: 0.0203 - val_loss: 0.0658 - val_acc: 0.0140\n",
      "Epoch 33/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0648 - acc: 0.0203 - val_loss: 0.0658 - val_acc: 0.0110\n",
      "Epoch 34/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0647 - acc: 0.0207 - val_loss: 0.0659 - val_acc: 0.0210\n",
      "Epoch 35/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0647 - acc: 0.0206 - val_loss: 0.0658 - val_acc: 0.0240\n",
      "Epoch 36/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0647 - acc: 0.0202 - val_loss: 0.0658 - val_acc: 0.0170\n",
      "Epoch 37/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0647 - acc: 0.0201 - val_loss: 0.0658 - val_acc: 0.0120\n",
      "Epoch 38/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0647 - acc: 0.0209 - val_loss: 0.0657 - val_acc: 0.0250\n",
      "Epoch 39/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0646 - acc: 0.0198 - val_loss: 0.0656 - val_acc: 0.0170\n",
      "Epoch 40/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0646 - acc: 0.0207 - val_loss: 0.0656 - val_acc: 0.0240\n",
      "Epoch 41/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0646 - acc: 0.0207 - val_loss: 0.0656 - val_acc: 0.0070\n",
      "Epoch 42/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0646 - acc: 0.0209 - val_loss: 0.0655 - val_acc: 0.0130\n",
      "Epoch 43/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0646 - acc: 0.0201 - val_loss: 0.0655 - val_acc: 0.0270\n",
      "Epoch 44/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0646 - acc: 0.0200 - val_loss: 0.0655 - val_acc: 0.0230\n",
      "Epoch 45/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0646 - acc: 0.0223 - val_loss: 0.0654 - val_acc: 0.0260\n",
      "Epoch 46/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0645 - acc: 0.0219 - val_loss: 0.0654 - val_acc: 0.0150\n",
      "Epoch 47/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0645 - acc: 0.0207 - val_loss: 0.0656 - val_acc: 0.0320\n",
      "Epoch 48/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0645 - acc: 0.0212 - val_loss: 0.0657 - val_acc: 0.0290\n",
      "Epoch 49/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0645 - acc: 0.0214 - val_loss: 0.0655 - val_acc: 0.0210\n",
      "Epoch 50/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0645 - acc: 0.0208 - val_loss: 0.0654 - val_acc: 0.0090\n",
      "Epoch 51/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0645 - acc: 0.0215 - val_loss: 0.0654 - val_acc: 0.0120\n",
      "Epoch 52/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0645 - acc: 0.0219 - val_loss: 0.0655 - val_acc: 0.0090\n",
      "Epoch 53/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0645 - acc: 0.0217 - val_loss: 0.0655 - val_acc: 0.0090\n",
      "Epoch 54/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0644 - acc: 0.0210 - val_loss: 0.0656 - val_acc: 0.0280\n",
      "Epoch 55/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0644 - acc: 0.0221 - val_loss: 0.0656 - val_acc: 0.0230\n",
      "Epoch 56/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0644 - acc: 0.0223 - val_loss: 0.0655 - val_acc: 0.0090\n",
      "Epoch 57/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0644 - acc: 0.0216 - val_loss: 0.0654 - val_acc: 0.0110\n",
      "Epoch 58/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0644 - acc: 0.0222 - val_loss: 0.0654 - val_acc: 0.0210\n",
      "Epoch 59/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0644 - acc: 0.0209 - val_loss: 0.0654 - val_acc: 0.0350\n",
      "Epoch 60/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0644 - acc: 0.0223 - val_loss: 0.0654 - val_acc: 0.0130\n",
      "Epoch 61/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0644 - acc: 0.0222 - val_loss: 0.0654 - val_acc: 0.0260\n",
      "Epoch 62/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0644 - acc: 0.0230 - val_loss: 0.0653 - val_acc: 0.0200\n",
      "Epoch 63/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0643 - acc: 0.0216 - val_loss: 0.0654 - val_acc: 0.0130\n",
      "Epoch 64/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0643 - acc: 0.0219 - val_loss: 0.0653 - val_acc: 0.0200\n",
      "Epoch 65/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0643 - acc: 0.0221 - val_loss: 0.0655 - val_acc: 0.0090\n",
      "Epoch 66/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0643 - acc: 0.0219 - val_loss: 0.0654 - val_acc: 0.0270\n",
      "Epoch 67/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0643 - acc: 0.0211 - val_loss: 0.0656 - val_acc: 0.0170\n",
      "Epoch 68/100\n",
      "1000000/1000000 [==============================] - 18s 18us/step - loss: 0.0643 - acc: 0.0223 - val_loss: 0.0655 - val_acc: 0.0250\n",
      "Epoch 69/100\n",
      "1000000/1000000 [==============================] - 18s 18us/step - loss: 0.0643 - acc: 0.0231 - val_loss: 0.0655 - val_acc: 0.0180\n",
      "Epoch 70/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0643 - acc: 0.0215 - val_loss: 0.0654 - val_acc: 0.0130\n",
      "Epoch 71/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0642 - acc: 0.0222 - val_loss: 0.0654 - val_acc: 0.0200\n",
      "Epoch 72/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0642 - acc: 0.0226 - val_loss: 0.0654 - val_acc: 0.0240\n",
      "Epoch 73/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0642 - acc: 0.0222 - val_loss: 0.0655 - val_acc: 0.0210\n",
      "Epoch 74/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0642 - acc: 0.0221 - val_loss: 0.0655 - val_acc: 0.0260\n",
      "Epoch 75/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0642 - acc: 0.0227 - val_loss: 0.0654 - val_acc: 0.0110\n",
      "Epoch 76/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0642 - acc: 0.0218 - val_loss: 0.0655 - val_acc: 0.0150\n",
      "Epoch 77/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0641 - acc: 0.0225 - val_loss: 0.0655 - val_acc: 0.0320\n",
      "Epoch 78/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0641 - acc: 0.0216 - val_loss: 0.0656 - val_acc: 0.0250\n",
      "Epoch 79/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0641 - acc: 0.0219 - val_loss: 0.0655 - val_acc: 0.0210\n",
      "Epoch 80/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0641 - acc: 0.0223 - val_loss: 0.0654 - val_acc: 0.0170\n",
      "Epoch 81/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0641 - acc: 0.0236 - val_loss: 0.0653 - val_acc: 0.0130\n",
      "Epoch 82/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0640 - acc: 0.0227 - val_loss: 0.0656 - val_acc: 0.0260\n",
      "Epoch 83/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0640 - acc: 0.0221 - val_loss: 0.0654 - val_acc: 0.0160\n",
      "Epoch 84/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0640 - acc: 0.0217 - val_loss: 0.0656 - val_acc: 0.0240\n",
      "Epoch 85/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0640 - acc: 0.0225 - val_loss: 0.0653 - val_acc: 0.0200\n",
      "Epoch 86/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0640 - acc: 0.0224 - val_loss: 0.0656 - val_acc: 0.0190\n",
      "Epoch 87/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0639 - acc: 0.0226 - val_loss: 0.0656 - val_acc: 0.0170\n",
      "Epoch 88/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0639 - acc: 0.0214 - val_loss: 0.0655 - val_acc: 0.0120\n",
      "Epoch 89/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0639 - acc: 0.0215 - val_loss: 0.0657 - val_acc: 0.0310\n",
      "Epoch 90/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0639 - acc: 0.0220 - val_loss: 0.0654 - val_acc: 0.0260\n",
      "Epoch 91/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0639 - acc: 0.0220 - val_loss: 0.0655 - val_acc: 0.0410\n",
      "Epoch 92/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0638 - acc: 0.0208 - val_loss: 0.0656 - val_acc: 0.0410\n",
      "Epoch 93/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0638 - acc: 0.0202 - val_loss: 0.0655 - val_acc: 0.0350\n",
      "Epoch 94/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0638 - acc: 0.0205 - val_loss: 0.0656 - val_acc: 0.0190\n",
      "Epoch 95/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0637 - acc: 0.0197 - val_loss: 0.0656 - val_acc: 0.0220\n",
      "Epoch 96/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0637 - acc: 0.0202 - val_loss: 0.0657 - val_acc: 0.0330\n",
      "Epoch 97/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0637 - acc: 0.0198 - val_loss: 0.0657 - val_acc: 0.0340\n",
      "Epoch 98/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0637 - acc: 0.0185 - val_loss: 0.0657 - val_acc: 0.0220\n",
      "Epoch 99/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0636 - acc: 0.0186 - val_loss: 0.0658 - val_acc: 0.0050\n",
      "Epoch 100/100\n",
      "1000000/1000000 [==============================] - 17s 17us/step - loss: 0.0636 - acc: 0.0186 - val_loss: 0.0658 - val_acc: 0.0110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x228c91ac828>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ReceviedBEC, codeword, \n",
    "          epochs=100,\n",
    "          batch_size=10000,\n",
    "          shuffle=True,\n",
    "          validation_data=(test_ReceviedBEC, test_codeword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model/model_BEC_p6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
