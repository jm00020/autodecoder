{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense, Input, Add\n",
    "from keras.models import Sequential, Model, load_model\n",
    "import scipy.special as sp\n",
    "\n",
    "from Source import AWGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_power=7\n",
    "CodeRate=0.5\n",
    "N_length=int(2**n_power)\n",
    "msg_length=int(CodeRate*N_length)\n",
    "frozen_length=N_length-msg_length\n",
    "codeNum =10**6\n",
    "test_codeNum = 10**3\n",
    "\n",
    "EbNo_Start=1.0  # in dB\n",
    "EbNo_delta=0.5 # in dB\n",
    "EbNo_Numbers=10 \n",
    "EbNo=np.arange(EbNo_Start,EbNo_Start+EbNo_Numbers*EbNo_delta,EbNo_delta)\n",
    "ebno=10.**(EbNo/10.)          # dB to real value 변환\n",
    "BER_BPSK_Uncoded=0.5*sp.erfc(np.sqrt(ebno))      # BPSK BER 공식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_All=AWGN.AllGeneratorMatrixPolarCode(n_power) ###생성행렬생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Z_AWGN,Z_decending_index_AWGN)=AWGN.BhanttacharyyaParameterAWGN(N_length, n_power, CodeRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectedBitsPositions = Z_decending_index_AWGN[frozen_length:]\n",
    "SelectedBitsPositions.sort()\n",
    "FrozenBitsPositions = Z_decending_index_AWGN[:frozen_length]\n",
    "FrozenBitsPositions.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg=np.random.randint(0,2,size=(codeNum, msg_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg,codeword, uncodedbits = AWGN.Encoding(msg, codeNum, N_length, n_power, msg_length, SelectedBitsPositions, G_All[n_power])\n",
    "ReceivedAWGN = AWGN.ReceivedCode(ebno[0], CodeRate,codeNum, N_length, codeword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_msg=np.random.randint(0,2,size=(test_codeNum, msg_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_msg, test_codeword, test_uncodedbits = AWGN.Encoding(test_msg, test_codeNum, N_length, n_power, msg_length, SelectedBitsPositions, \n",
    "#                                         G_All[n_power]) \n",
    "test_ReceivedAWGN = AWGN.ReceivedCode(ebno[0], CodeRate,codeNum, N_length, codeword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(128,))\n",
    "\n",
    "line1_Dense1 = Dense(128*1, activation='elu')(input_layer)\n",
    "line1_Dense2 = Dense(128*1, activation='elu')(line1_Dense1)         \n",
    "line1_Dense3 = Dense(128*1, activation='elu')(line1_Dense2)\n",
    "line1_output_layer = Dense(128, activation='tanh')(line1_Dense3)\n",
    "\n",
    "line2_Dense1 = Dense(128*2, activation='elu')(input_layer)\n",
    "line2_Dense2 = Dense(128*4, activation='elu')(line2_Dense1)         \n",
    "line2_Dense3 = Dense(128*2, activation='elu')(line2_Dense2)\n",
    "line2_output_layer = Dense(128, activation='tanh')(line2_Dense3)\n",
    "\n",
    "line3_Dense1 = Dense(128*3, activation='elu')(input_layer)\n",
    "line3_Dense2 = Dense(128*9, activation='elu')(line3_Dense1)         \n",
    "line3_Dense3 = Dense(128*3, activation='elu')(line3_Dense2)\n",
    "line3_output_layer = Dense(128, activation='tanh')(line3_Dense3)\n",
    "\n",
    "line4_Dense1 = Dense(128*4, activation='elu')(input_layer)\n",
    "line4_Dense2 = Dense(128*16, activation='elu')(line4_Dense1)         \n",
    "line4_Dense3 = Dense(128*4, activation='elu')(line4_Dense2)\n",
    "line4_output_layer = Dense(128, activation='tanh')(line4_Dense3)\n",
    "\n",
    "line5_Dense1 = Dense(128*5, activation='elu')(input_layer)\n",
    "line5_Dense2 = Dense(128*25, activation='elu')(line5_Dense1)         \n",
    "line5_Dense3 = Dense(128*5, activation='elu')(line5_Dense2)\n",
    "line5_output_layer = Dense(128, activation='tanh')(line5_Dense3)\n",
    "\n",
    "line6_Dense1 = Dense(128*6, activation='elu')(input_layer)\n",
    "line6_Dense2 = Dense(128*36, activation='elu')(line6_Dense1)         \n",
    "line6_Dense3 = Dense(128*6, activation='elu')(line6_Dense2)\n",
    "line6_output_layer = Dense(128, activation='tanh')(line6_Dense3)\n",
    "\n",
    "add_layer = Add()([line1_output_layer, line2_output_layer, line3_output_layer, line4_output_layer, \n",
    "                   line5_output_layer, line6_output_layer])\n",
    "\n",
    "\n",
    "output_layer = Dense(64, activation='sigmoid')(add_layer)\n",
    "\n",
    "model = Model(inputs = input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1000000 samples, validate on 1000000 samples\n",
      "Epoch 1/100\n",
      "1000000/1000000 [==============================] - 23s 23us/step - loss: 0.7159 - accuracy: 0.5213 - val_loss: 0.6736 - val_accuracy: 0.5359\n",
      "Epoch 2/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6693 - accuracy: 0.5393 - val_loss: 0.6678 - val_accuracy: 0.5383\n",
      "Epoch 3/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6653 - accuracy: 0.5442 - val_loss: 0.6660 - val_accuracy: 0.5408\n",
      "Epoch 4/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6636 - accuracy: 0.5488 - val_loss: 0.6647 - val_accuracy: 0.5440\n",
      "Epoch 5/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6621 - accuracy: 0.5538 - val_loss: 0.6637 - val_accuracy: 0.5482\n",
      "Epoch 6/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6601 - accuracy: 0.5600 - val_loss: 0.6617 - val_accuracy: 0.5546\n",
      "Epoch 7/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6570 - accuracy: 0.5668 - val_loss: 0.6580 - val_accuracy: 0.5619\n",
      "Epoch 8/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6530 - accuracy: 0.5730 - val_loss: 0.6542 - val_accuracy: 0.5674\n",
      "Epoch 9/100\n",
      "1000000/1000000 [==============================] - 23s 23us/step - loss: 0.6488 - accuracy: 0.5784 - val_loss: 0.6506 - val_accuracy: 0.5719\n",
      "Epoch 10/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6450 - accuracy: 0.5826 - val_loss: 0.6480 - val_accuracy: 0.5746\n",
      "Epoch 11/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6422 - accuracy: 0.5857 - val_loss: 0.6461 - val_accuracy: 0.5764\n",
      "Epoch 12/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6401 - accuracy: 0.5882 - val_loss: 0.6448 - val_accuracy: 0.5777\n",
      "Epoch 13/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6383 - accuracy: 0.5903 - val_loss: 0.6442 - val_accuracy: 0.5786\n",
      "Epoch 14/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6368 - accuracy: 0.5923 - val_loss: 0.6432 - val_accuracy: 0.5800\n",
      "Epoch 15/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6351 - accuracy: 0.5944 - val_loss: 0.6420 - val_accuracy: 0.5817\n",
      "Epoch 16/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6326 - accuracy: 0.5971 - val_loss: 0.6399 - val_accuracy: 0.5841\n",
      "Epoch 17/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6299 - accuracy: 0.5996 - val_loss: 0.6380 - val_accuracy: 0.5861\n",
      "Epoch 18/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6272 - accuracy: 0.6021 - val_loss: 0.6366 - val_accuracy: 0.5876\n",
      "Epoch 19/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6246 - accuracy: 0.6043 - val_loss: 0.6350 - val_accuracy: 0.5892\n",
      "Epoch 20/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6221 - accuracy: 0.6066 - val_loss: 0.6340 - val_accuracy: 0.5903\n",
      "Epoch 21/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6194 - accuracy: 0.6088 - val_loss: 0.6327 - val_accuracy: 0.5919\n",
      "Epoch 22/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6164 - accuracy: 0.6114 - val_loss: 0.6311 - val_accuracy: 0.5932\n",
      "Epoch 23/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6134 - accuracy: 0.6139 - val_loss: 0.6303 - val_accuracy: 0.5941\n",
      "Epoch 24/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6106 - accuracy: 0.6163 - val_loss: 0.6297 - val_accuracy: 0.5948\n",
      "Epoch 25/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6078 - accuracy: 0.6187 - val_loss: 0.6303 - val_accuracy: 0.5949\n",
      "Epoch 26/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6051 - accuracy: 0.6210 - val_loss: 0.6306 - val_accuracy: 0.5951\n",
      "Epoch 27/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.6023 - accuracy: 0.6234 - val_loss: 0.6320 - val_accuracy: 0.5949\n",
      "Epoch 28/100\n",
      "1000000/1000000 [==============================] - 23s 23us/step - loss: 0.5994 - accuracy: 0.6260 - val_loss: 0.6329 - val_accuracy: 0.5949\n",
      "Epoch 29/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.5963 - accuracy: 0.6287 - val_loss: 0.6344 - val_accuracy: 0.5946\n",
      "Epoch 30/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.5930 - accuracy: 0.6315 - val_loss: 0.6359 - val_accuracy: 0.5944\n",
      "Epoch 31/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.5895 - accuracy: 0.6344 - val_loss: 0.6382 - val_accuracy: 0.5938\n",
      "Epoch 32/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.5860 - accuracy: 0.6372 - val_loss: 0.6411 - val_accuracy: 0.5934\n",
      "Epoch 33/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.5822 - accuracy: 0.6403 - val_loss: 0.6439 - val_accuracy: 0.5927\n",
      "Epoch 34/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.5783 - accuracy: 0.6432 - val_loss: 0.6470 - val_accuracy: 0.5922\n",
      "Epoch 35/100\n",
      "1000000/1000000 [==============================] - 22s 22us/step - loss: 0.5742 - accuracy: 0.6464 - val_loss: 0.6506 - val_accuracy: 0.5916\n",
      "Epoch 36/100\n",
      " 290000/1000000 [=======>......................] - ETA: 11s - loss: 0.5655 - accuracy: 0.6532"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6f6d350c4232>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m           validation_data=(test_ReceivedAWGN,msg))\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(ReceivedAWGN, msg, \n",
    "          epochs=25,\n",
    "          batch_size=10000,\n",
    "          shuffle=True,\n",
    "          validation_data=(test_ReceivedAWGN,msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6392131280899048, 0.586062490940094]\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(test_ReceivedAWGN, msg, verbose=0)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model/model_AWGN_p6_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
