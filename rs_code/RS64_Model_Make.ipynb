{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Source import RS64_Encoder\n",
    "from Source import RS64_Decoder\n",
    "from Source.GF64 import GFE\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Input,Conv1D, MaxPooling1D, Flatten, Embedding, Reshape, ReLU, Add, Concatenate, Average\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 6\n",
    "t_RS = 8\n",
    "b_RS = 1\n",
    "order_alpha=(2**m)-1\n",
    "length_parity=2*t_RS\n",
    "n_RS=order_alpha\n",
    "k_RS=n_RS - length_parity\n",
    "\n",
    "Z_RS=[]\n",
    "for i in range(2*t_RS):    \n",
    "    Z_RS.append((b_RS+i)%order_alpha)\n",
    "    \n",
    "g_x = RS64_Encoder.Generation_Polynomial(Z_RS, order_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "codeword_size = 10**6\n",
    "# codeword_RS = RS64_Encoder.Encoder(m, t_RS, b_RS, order_alpha, k_RS, Z_RS, g_x, codeword_size)\n",
    "\n",
    "# cx = np.power(-1,GFE[(codeword_RS+1).astype(np.int)])\n",
    "# cx = cx.reshape((codeword_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = np.random.randint(2, size=(codeword_size, 378))\n",
    "cx = np.where(cx > 0, -1, 1)\n",
    "cx = cx.reshape((codeword_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eb_No = 3\n",
    "rx = RS64_Decoder.Receive_Bit(Eb_No, cx, k_RS, n_RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### model make####\n",
    "input_layer = Input(shape=(378,))\n",
    "line1_Dense1 = Dense(126, activation='elu')(input_layer)\n",
    "line1_Dense2 = Dense(42, activation='elu')(line1_Dense1)\n",
    "line1_Dense3 = Dense(126, activation='elu')(line1_Dense2)\n",
    "line1_output_layer = Dense(378, activation='tanh')(line1_Dense1)\n",
    "\n",
    "line2_Dense1 = Dense(189, activation='elu')(input_layer)\n",
    "line2_Dense2 = Dense(95, activation='elu')(line2_Dense1)\n",
    "line2_Dense3 = Dense(189, activation='elu')(line2_Dense2)\n",
    "line2_output_layer = Dense(378, activation='tanh')(line2_Dense3)\n",
    "\n",
    "line3_Dense1 = Dense(378, activation='elu')(input_layer)\n",
    "line3_Dense2 = Dense(378, activation='elu')(line3_Dense1)         \n",
    "line3_Dense3 = Dense(378, activation='elu')(line3_Dense2)\n",
    "line3_output_layer = Dense(378, activation='tanh')(line3_Dense3)\n",
    "\n",
    "line4_Dense1 = Dense(756, activation='elu')(input_layer)\n",
    "line4_Dense2 = Dense(1512, activation='elu')(line4_Dense1)         \n",
    "line4_Dense3 = Dense(756, activation='elu')(line4_Dense2)\n",
    "line4_output_layer = Dense(378, activation='tanh')(line4_Dense3)\n",
    "\n",
    "line5_Dense1 = Dense(1134, activation='elu')(input_layer)\n",
    "line5_Dense2 = Dense(3402, activation='elu')(line5_Dense1)         \n",
    "line5_Dense3 = Dense(1134, activation='elu')(line5_Dense2)\n",
    "line5_output_layer = Dense(378, activation='tanh')(line5_Dense3)\n",
    "\n",
    "add_layer = Add()([line1_output_layer, line2_output_layer, line3_output_layer, line4_output_layer, line5_output_layer])\n",
    "\n",
    "output_layer = Dense(378, activation='sigmoid')(add_layer)\n",
    "\n",
    "model = Model(inputs = input_layer, outputs = output_layer)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_cross_entropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700000/700000 [==============================] - 16s 23us/step - loss: 0.2490 - acc: 0.0056 - val_loss: 0.2648 - val_acc: 0.0065\n",
      "Epoch 88/100\n",
      "700000/700000 [==============================] - 16s 23us/step - loss: 0.2487 - acc: 0.0055 - val_loss: 0.2646 - val_acc: 0.0051\n",
      "Epoch 89/100\n",
      "700000/700000 [==============================] - 17s 24us/step - loss: 0.2485 - acc: 0.0055 - val_loss: 0.2645 - val_acc: 0.0053\n",
      "Epoch 90/100\n",
      "700000/700000 [==============================] - 16s 23us/step - loss: 0.2483 - acc: 0.0056 - val_loss: 0.2646 - val_acc: 0.0057\n",
      "Epoch 91/100\n",
      "700000/700000 [==============================] - 16s 23us/step - loss: 0.2481 - acc: 0.0056 - val_loss: 0.2647 - val_acc: 0.0055\n",
      "Epoch 92/100\n",
      "700000/700000 [==============================] - 16s 23us/step - loss: 0.2480 - acc: 0.0055 - val_loss: 0.2649 - val_acc: 0.0056\n",
      "Epoch 93/100\n",
      "700000/700000 [==============================] - 16s 23us/step - loss: 0.2479 - acc: 0.0055 - val_loss: 0.2648 - val_acc: 0.0051\n",
      "Epoch 94/100\n",
      "700000/700000 [==============================] - 16s 23us/step - loss: 0.2478 - acc: 0.0054 - val_loss: 0.2649 - val_acc: 0.0057\n",
      "Epoch 95/100\n",
      "700000/700000 [==============================] - 16s 23us/step - loss: 0.2477 - acc: 0.0055 - val_loss: 0.2651 - val_acc: 0.0058\n",
      "Epoch 96/100\n",
      "700000/700000 [==============================] - 17s 24us/step - loss: 0.2476 - acc: 0.0055 - val_loss: 0.2652 - val_acc: 0.0054\n",
      "Epoch 97/100\n",
      "700000/700000 [==============================] - 17s 24us/step - loss: 0.2474 - acc: 0.0056 - val_loss: 0.2652 - val_acc: 0.0057\n",
      "Epoch 98/100\n",
      "700000/700000 [==============================] - 17s 24us/step - loss: 0.2473 - acc: 0.0055 - val_loss: 0.2654 - val_acc: 0.0053\n",
      "Epoch 99/100\n",
      "700000/700000 [==============================] - 16s 23us/step - loss: 0.2472 - acc: 0.0056 - val_loss: 0.2655 - val_acc: 0.0045\n",
      "Epoch 100/100\n",
      "700000/700000 [==============================] - 16s 23us/step - loss: 0.2471 - acc: 0.0055 - val_loss: 0.2655 - val_acc: 0.0058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b6931e0828>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(rx[:int(0.7*codeword_size)], cx[:int(0.7*codeword_size)], \n",
    "          epochs=100,\n",
    "          batch_size=10000,\n",
    "          shuffle=True,\n",
    "          validation_data=(rx[int(0.7*codeword_size):], cx[int(0.7*codeword_size):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vector_RS = model.predict(r_vector_RS)\n",
    "print(pred_vector_RS)\n",
    "pred_vector_RS = np.reshape(pred_vector_RS,[codeword_size, n_RS]) \n",
    "pred_vector_RS = np.rint(pred_vector_RS* order_alpha) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_vector_RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndrome_RS = []\n",
    "syndrome_check = []\n",
    "for i in range(codeword_size):\n",
    "    s_RS, s_c = RS64_Decoder.Syndrome_Check(t_RS, pred_vector_RS[i], order_alpha, Z_RS)\n",
    "    syndrome_RS.extend(s_RS)\n",
    "    syndrome_check.append(s_c)\n",
    "syndrome_RS = np.reshape(syndrome_RS, [codeword_size, 2*t_RS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimated_Codeword = []\n",
    "for i in range(codeword_size):\n",
    "    E_Codeword = RS64_Decoder.Decoder(syndrome_RS[i], syndrome_check[i], pred_vector_RS[i], t_RS, order_alpha, m)\n",
    "    Estimated_Codeword.extend(E_Codeword)\n",
    "Estimated_Codeword = np.reshape(Estimated_Codeword, [codeword_size, n_RS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimated_Message=Estimated_Codeword[:,length_parity:]\n",
    "msg_RS = codeword_RS[:,length_parity:]\n",
    "\n",
    "Symbol_error_count=0\n",
    "for i  in range(codeword_size):\n",
    "    for j in range(k_RS):\n",
    "        if Estimated_Message[i][j] != msg_RS[i][j]:\n",
    "            Symbol_error_count+=1\n",
    "    \n",
    "SER=Symbol_error_count/(codeword_size*k_RS)\n",
    "\n",
    "print(\"Symbol Error Rate:\",SER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
